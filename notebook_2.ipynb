{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PDF files and split that into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"../local-model/sample-pdf\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SentenceSplitter(chunk_size=200, chunk_overlap=50)\n",
    "nodes = text_splitter.get_nodes_from_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 pages\n",
      "18 nodes\n"
     ]
    }
   ],
   "source": [
    "print(len(documents), 'pages')\n",
    "print(len(nodes), 'nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Chroma as vector db and load Llama3-8B as embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create client and a new collection\n",
    "chroma_client = chromadb.EphemeralClient()\n",
    "chroma_collection = chroma_client.create_collection(\"percobaan\")\n",
    "\n",
    "# define embedding function\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "\n",
    "# set up ChromaVectorStore and load in data\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = VectorStoreIndex.from_documents(\n",
    "#     documents, storage_context=storage_context, embed_model=ollama_embedding\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(nodes=nodes, storage_context=storage_context, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create retriever and load Llama3-8B as LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='0e72dd7a-aab1-4744-acbf-d136930b33e1', embedding=None, metadata={'page_label': '2', 'file_name': '12_hl2090.pdf', 'file_path': 'c:\\\\Users\\\\lebnovo\\\\llamaindex\\\\..\\\\local-model\\\\sample-pdf\\\\12_hl2090.pdf', 'file_type': 'application/pdf', 'file_size': 211936, 'creation_date': '2024-07-07', 'last_modified_date': '2024-07-07'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='9106a0cd-d8c3-49ce-a8b9-d6f87d39d9e3', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '2', 'file_name': '12_hl2090.pdf', 'file_path': 'c:\\\\Users\\\\lebnovo\\\\llamaindex\\\\..\\\\local-model\\\\sample-pdf\\\\12_hl2090.pdf', 'file_type': 'application/pdf', 'file_size': 211936, 'creation_date': '2024-07-07', 'last_modified_date': '2024-07-07'}, hash='bcb998b5ce043779a0fa8eeda9fad8ecf51d28b8227e7d06a84f6e1aa30a2743'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='19efc032-68ba-487f-a660-5f3c0cded297', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '2', 'file_name': '12_hl2090.pdf', 'file_path': 'c:\\\\Users\\\\lebnovo\\\\llamaindex\\\\..\\\\local-model\\\\sample-pdf\\\\12_hl2090.pdf', 'file_type': 'application/pdf', 'file_size': 211936, 'creation_date': '2024-07-07', 'last_modified_date': '2024-07-07'}, hash='4a245c0d9b45d88b2770558538f38aa7997d8988e47b84d0f30134b2bcc4609a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c9d0dd43-1d44-4809-8a1f-ba768018df36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='44d8992fa6b0d13273bffe38c97824841f2101669596bb985b1b1e379fadf68c')}, text='Those who are absent for presentations will not \\nhave the opportunity to make -up their work in another group’s presentation. \\n \\n• Any attempt at plagia rism will be subjected to university disciplinary action . Please \\nfamiliarize yourself with NTU’s Academic Integrity Guidelines to avoid plagiarism: \\nhttp://www.ntu.edu.sg/ai/Pages/academic -integrity -policy.aspx \\n Course Assessment  \\n Participation                10% \\nPresentation      10% \\nCreative project     40% \\nEssay       40% \\n Required Texts:  \\n Dos Passos, John. Manhattan Transfer . \\n Fitzgerald, F. Scott. The Great Gatsby.  Mohsin, Hamid. How to Get Filthy Rich in Rising Asia .', mimetype='text/plain', start_char_idx=539, end_char_idx=1186, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5389475290053828),\n",
       " NodeWithScore(node=TextNode(id_='61dbdf1d-0ecc-4464-a757-2a1c17a95d08', embedding=None, metadata={'page_label': '1', 'file_name': 'english-test-scores.pdf', 'file_path': 'c:\\\\Users\\\\lebnovo\\\\llamaindex\\\\..\\\\local-model\\\\sample-pdf\\\\english-test-scores.pdf', 'file_type': 'application/pdf', 'file_size': 124513, 'creation_date': '2024-07-07', 'last_modified_date': '2024-07-07'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='540053cb-1433-4182-80c0-2e779312905e', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '1', 'file_name': 'english-test-scores.pdf', 'file_path': 'c:\\\\Users\\\\lebnovo\\\\llamaindex\\\\..\\\\local-model\\\\sample-pdf\\\\english-test-scores.pdf', 'file_type': 'application/pdf', 'file_size': 124513, 'creation_date': '2024-07-07', 'last_modified_date': '2024-07-07'}, hash='039b481677be1562c8061776b346b6ee997f1ef3672c8c696845023fb603b82f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='374f9d87-47df-47ff-8eca-c437b9155729', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '1', 'file_name': 'english-test-scores.pdf', 'file_path': 'c:\\\\Users\\\\lebnovo\\\\llamaindex\\\\..\\\\local-model\\\\sample-pdf\\\\english-test-scores.pdf', 'file_type': 'application/pdf', 'file_size': 124513, 'creation_date': '2024-07-07', 'last_modified_date': '2024-07-07'}, hash='4711b27f30022f0444159dad2584e28780a97032b76914cf310903f8605b74b9')}, text='The score report must reach the Office of Admissions by your \\napplication closing date , failing which your application will be deemed incomplete  and will not be \\nprocessed.  \\n \\n# IELTS  Indicator  score  is not accepted.  \\n* NUS only accepts  TOEFL  iBT scores  from  a single  test date,  not MyBest  scores.  \\n^ Attained  a minimum  of ‘B1’ in EL1119  examination,  graded  based  on CEFR  Level.  \\n \\n  \\n \\n1', mimetype='text/plain', start_char_idx=1522, end_char_idx=1933, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.45472195761165923)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.retrieve(\"What's the website that provide NTU Academic Integrity Guidelines?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.ntu.edu.sg/ai/Pages/academic-integrity-policy.aspx\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama3:latest\", request_timeout=60.0)\n",
    "query_engine = index.as_query_engine(llm=llm)\n",
    "response = query_engine.query(\"What's the website that provide NTU Academic Integrity Guidelines?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response_synthesizer:text_qa_template': SelectorPromptTemplate(metadata={'prompt_type': <PromptType.QUESTION_ANSWER: 'text_qa'>}, template_vars=['context_str', 'query_str'], kwargs={}, output_parser=None, template_var_mappings={}, function_mappings={}, default_template=PromptTemplate(metadata={'prompt_type': <PromptType.QUESTION_ANSWER: 'text_qa'>}, template_vars=['context_str', 'query_str'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, template='Context information is below.\\n---------------------\\n{context_str}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {query_str}\\nAnswer: '), conditionals=[(<function is_chat_model at 0x00000264190800E0>, ChatPromptTemplate(metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>}, template_vars=['context_str', 'query_str'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, message_templates=[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content=\"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\", additional_kwargs={}), ChatMessage(role=<MessageRole.USER: 'user'>, content='Context information is below.\\n---------------------\\n{context_str}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {query_str}\\nAnswer: ', additional_kwargs={})]))]),\n",
       " 'response_synthesizer:refine_template': SelectorPromptTemplate(metadata={'prompt_type': <PromptType.REFINE: 'refine'>}, template_vars=['query_str', 'existing_answer', 'context_msg'], kwargs={}, output_parser=None, template_var_mappings={}, function_mappings={}, default_template=PromptTemplate(metadata={'prompt_type': <PromptType.REFINE: 'refine'>}, template_vars=['query_str', 'existing_answer', 'context_msg'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, template=\"The original query is as follows: {query_str}\\nWe have provided an existing answer: {existing_answer}\\nWe have the opportunity to refine the existing answer (only if needed) with some more context below.\\n------------\\n{context_msg}\\n------------\\nGiven the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\nRefined Answer: \"), conditionals=[(<function is_chat_model at 0x00000264190800E0>, ChatPromptTemplate(metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>}, template_vars=['context_msg', 'query_str', 'existing_answer'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, message_templates=[ChatMessage(role=<MessageRole.USER: 'user'>, content=\"You are an expert Q&A system that strictly operates in two modes when refining existing answers:\\n1. **Rewrite** an original answer using the new context.\\n2. **Repeat** the original answer if the new context isn't useful.\\nNever reference the original answer or context directly in your answer.\\nWhen in doubt, just repeat the original answer.\\nNew Context: {context_msg}\\nQuery: {query_str}\\nOriginal Answer: {existing_answer}\\nNew Answer: \", additional_kwargs={})]))])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_dict = query_engine.get_prompts()\n",
    "prompts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "template = (\n",
    "    \"\"\"\n",
    "    Answer the question based on the context below. If you can't \n",
    "    answer the question, reply \"I don't know\".\n",
    "\n",
    "    Context: {context_str}\n",
    "\n",
    "    Question: {query_str}\n",
    "    \"\"\"\n",
    ")\n",
    "qa_template = PromptTemplate(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_template}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response_synthesizer:text_qa_template': PromptTemplate(metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>}, template_vars=['context_str', 'query_str'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, template='\\n    Answer the question based on the context below. If you can\\'t \\n    answer the question, reply \"I don\\'t know\".\\n\\n    Context: {context_str}\\n\\n    Question: {query_str}\\n    '),\n",
       " 'response_synthesizer:refine_template': SelectorPromptTemplate(metadata={'prompt_type': <PromptType.REFINE: 'refine'>}, template_vars=['query_str', 'existing_answer', 'context_msg'], kwargs={}, output_parser=None, template_var_mappings={}, function_mappings={}, default_template=PromptTemplate(metadata={'prompt_type': <PromptType.REFINE: 'refine'>}, template_vars=['query_str', 'existing_answer', 'context_msg'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, template=\"The original query is as follows: {query_str}\\nWe have provided an existing answer: {existing_answer}\\nWe have the opportunity to refine the existing answer (only if needed) with some more context below.\\n------------\\n{context_msg}\\n------------\\nGiven the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\nRefined Answer: \"), conditionals=[(<function is_chat_model at 0x00000264190800E0>, ChatPromptTemplate(metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>}, template_vars=['context_msg', 'query_str', 'existing_answer'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, message_templates=[ChatMessage(role=<MessageRole.USER: 'user'>, content=\"You are an expert Q&A system that strictly operates in two modes when refining existing answers:\\n1. **Rewrite** an original answer using the new context.\\n2. **Repeat** the original answer if the new context isn't useful.\\nNever reference the original answer or context directly in your answer.\\nWhen in doubt, just repeat the original answer.\\nNew Context: {context_msg}\\nQuery: {query_str}\\nOriginal Answer: {existing_answer}\\nNew Answer: \", additional_kwargs={})]))])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_dict = query_engine.get_prompts()\n",
    "prompts_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is: http://www.ntu.edu.sg/ai/Pages/academic-integrity-policy.aspx\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What's the website that provide NTU Academic Integrity Guidelines?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the main focus of the course HL 2090 Special Topic in Literature, I: Literature and Economics?\n",
      "Answer: The main focus of the course HL 2090 Special Topic in Literature, I: Literature and Economics is an introduction to economic concepts and ideas through their dramatization in literature.\n",
      "\n",
      "Question: What's the website that provide NTU Academic Integrity Guidelines?\n",
      "Answer: http://www.ntu.edu.sg/ai/Pages/academic-integrity-policy.aspx\n",
      "\n",
      "Question: What if you wish to use the materials for your assignments?\n",
      "Answer: If you wish to use the materials for your assignments, you must cite them accordingly.\n",
      "\n",
      "Question: Can you list the books mentioned in the course?\n",
      "Answer: Based on the context provided, here is the list of books mentioned in the course:\n",
      "\n",
      "1. \"The Way to Wealth\" by Benjamin Franklin\n",
      "2. \"Bartleby the Scrivener\" by Herman Melville\n",
      "3. \"The Great Gatsby\" by F. Scott Fitzgerald\n",
      "4. \"Crazy Rich Asians\" by Kevin Kwan\n",
      "5. \"Manhattan Transfer\" by John Dos Passos\n",
      "6. \"McTeague\" by Frank Norris\n",
      "7. \"Daughter of Earth\" by Agnes Smedley\n",
      "8. \"How to Get Filthy Rich in Rising Asia\" by Mohsin Hamid\n",
      "\n",
      "Let me know if you have any further questions!\n",
      "\n",
      "Question: Can you provide the English Language requirement?\n",
      "Answer: According to the context, the English Language requirement is:\n",
      "\n",
      "* C1 Advanced (180)\n",
      "* EL1119 C6 (Examination taken in 2020 or earlier)\n",
      "* B1 (Examination taken from 2021 onwards)\n",
      "* IELTS # 6.5 overall with 6.\n",
      "\n",
      "Note that these requirements are specified for certain qualifications, and applicants may need to furnish additional English Language test scores beyond their high school qualifications.\n",
      "\n",
      "Question: What is the minimum acceptable score for the TOEFL iBT test?\n",
      "Answer: I don't know. The text does not specify a minimum acceptable score for the TOEFL iBT test. It only mentions that NUS only accepts TOEFL iBT scores from a single test date, and that IELTS Indicator score is not accepted.\n",
      "\n",
      "Question: How long is the validity of the MUET score?\n",
      "Answer: According to the context, the answer is \"five years\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What is the main focus of the course HL 2090 Special Topic in Literature, I: Literature and Economics?\",\n",
    "    \"What's the website that provide NTU Academic Integrity Guidelines?\",\n",
    "    \"What if you wish to use the materials for your assignments?\",\n",
    "    \"Can you list the books mentioned in the course?\",\n",
    "    \"Can you provide the English Language requirement?\",\n",
    "    \"What is the minimum acceptable score for the TOEFL iBT test?\",\n",
    "    \"How long is the validity of the MUET score?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    response = query_engine.query(question)\n",
    "    print(f\"Answer: {response}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
